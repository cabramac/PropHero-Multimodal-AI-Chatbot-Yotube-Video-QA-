{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "279bd8c6",
   "metadata": {},
   "source": [
    "**Key Objectives Delivered**:\n",
    "1) **Video Data Indexing** --> Loaded the structured Yotube transcripts generated in Notebook 1 for further processing. \n",
    "2) **Blog Ingestion** --> Retrieved and cleaned text from multiple PropHero blogs URLs. \n",
    "3) **Text Cleaning** --> Applied preprocessing helper functions to normalize text, remove noise.\n",
    "4) **Text Chunking** --> Split both Yotube transcripts and blog articles into overlapping chunks with LangChain (RecursiveCharacterTextSplitter). \n",
    "- Yotube --> chunk size = 600 / overlap = 100. \n",
    "- Blogs --> chunk size = 800 / overlap = 100\n",
    "5) **Embeddings Creation** --> Generated semantic vector embeddings for all chunks using (sentence-transformers/all-MiniLM-L6-v2)\n",
    "6) **Chroma Vector DB** --> Stored the embeddings (videos + blogs) into Chroma collection for future retrieval in the QA system. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2794793",
   "metadata": {},
   "source": [
    "**2. Indexing Base Builder RAG System** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c11a2f",
   "metadata": {},
   "source": [
    "2.1 Loading all .json from data/transcript (videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3709db41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers==2.7.0 in c:\\users\\macat\\anaconda3\\envs\\langchain-mq\\lib\\site-packages (2.7.0)\n",
      "Requirement already satisfied: transformers==4.39.3 in c:\\users\\macat\\anaconda3\\envs\\langchain-mq\\lib\\site-packages (4.39.3)\n",
      "Requirement already satisfied: huggingface_hub==0.20.0 in c:\\users\\macat\\anaconda3\\envs\\langchain-mq\\lib\\site-packages (0.20.0)\n",
      "Requirement already satisfied: protobuf<=3.20.3 in c:\\users\\macat\\anaconda3\\envs\\langchain-mq\\lib\\site-packages (3.20.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\macat\\anaconda3\\envs\\langchain-mq\\lib\\site-packages (from sentence-transformers==2.7.0) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\macat\\anaconda3\\envs\\langchain-mq\\lib\\site-packages (from sentence-transformers==2.7.0) (2.9.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\macat\\anaconda3\\envs\\langchain-mq\\lib\\site-packages (from sentence-transformers==2.7.0) (2.3.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\macat\\anaconda3\\envs\\langchain-mq\\lib\\site-packages (from sentence-transformers==2.7.0) (1.7.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\macat\\anaconda3\\envs\\langchain-mq\\lib\\site-packages (from sentence-transformers==2.7.0) (1.16.3)\n",
      "Requirement already satisfied: Pillow in c:\\users\\macat\\anaconda3\\envs\\langchain-mq\\lib\\site-packages (from sentence-transformers==2.7.0) (12.0.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\macat\\anaconda3\\envs\\langchain-mq\\lib\\site-packages (from transformers==4.39.3) (3.20.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\macat\\anaconda3\\envs\\langchain-mq\\lib\\site-packages (from transformers==4.39.3) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\macat\\anaconda3\\envs\\langchain-mq\\lib\\site-packages (from transformers==4.39.3) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\macat\\anaconda3\\envs\\langchain-mq\\lib\\site-packages (from transformers==4.39.3) (2025.11.3)\n",
      "Requirement already satisfied: requests in c:\\users\\macat\\anaconda3\\envs\\langchain-mq\\lib\\site-packages (from transformers==4.39.3) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\macat\\anaconda3\\envs\\langchain-mq\\lib\\site-packages (from transformers==4.39.3) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\macat\\anaconda3\\envs\\langchain-mq\\lib\\site-packages (from transformers==4.39.3) (0.6.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\macat\\anaconda3\\envs\\langchain-mq\\lib\\site-packages (from huggingface_hub==0.20.0) (2025.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\macat\\anaconda3\\envs\\langchain-mq\\lib\\site-packages (from huggingface_hub==0.20.0) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\macat\\anaconda3\\envs\\langchain-mq\\lib\\site-packages (from torch>=1.11.0->sentence-transformers==2.7.0) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\macat\\anaconda3\\envs\\langchain-mq\\lib\\site-packages (from torch>=1.11.0->sentence-transformers==2.7.0) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\macat\\anaconda3\\envs\\langchain-mq\\lib\\site-packages (from torch>=1.11.0->sentence-transformers==2.7.0) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\macat\\anaconda3\\envs\\langchain-mq\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers==2.7.0) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\macat\\anaconda3\\envs\\langchain-mq\\lib\\site-packages (from tqdm->sentence-transformers==2.7.0) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\macat\\anaconda3\\envs\\langchain-mq\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers==2.7.0) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\macat\\anaconda3\\envs\\langchain-mq\\lib\\site-packages (from requests->transformers==4.39.3) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\macat\\anaconda3\\envs\\langchain-mq\\lib\\site-packages (from requests->transformers==4.39.3) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\macat\\anaconda3\\envs\\langchain-mq\\lib\\site-packages (from requests->transformers==4.39.3) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\macat\\anaconda3\\envs\\langchain-mq\\lib\\site-packages (from requests->transformers==4.39.3) (2025.11.12)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\macat\\anaconda3\\envs\\langchain-mq\\lib\\site-packages (from scikit-learn->sentence-transformers==2.7.0) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\macat\\anaconda3\\envs\\langchain-mq\\lib\\site-packages (from scikit-learn->sentence-transformers==2.7.0) (3.6.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install \"sentence-transformers==2.7.0\" \\\n",
    "             \"transformers==4.39.3\" \\\n",
    "             \"huggingface_hub==0.20.0\" \\\n",
    "             \"protobuf<=3.20.3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382b1055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 transcript files in data/transcripts:\n",
      " - prophero_video_1.json\n",
      " - prophero_video_2.json\n",
      " - prophero_video_3.json\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>num_segments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>prophero_video_1</td>\n",
       "      <td>PropHero – Intro Video 1</td>\n",
       "      <td>https://www.youtube.com/watch?v=ED3eypjlfrY</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>prophero_video_2</td>\n",
       "      <td>PropHero – Intro Video 2</td>\n",
       "      <td>https://www.youtube.com/watch?v=uxF2IObEzZg</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>prophero_video_3</td>\n",
       "      <td>PropHero – Intro Video 3</td>\n",
       "      <td>https://www.youtube.com/watch?v=5Kca3nOrefY</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           video_id                     title  \\\n",
       "0  prophero_video_1  PropHero – Intro Video 1   \n",
       "1  prophero_video_2  PropHero – Intro Video 2   \n",
       "2  prophero_video_3  PropHero – Intro Video 3   \n",
       "\n",
       "                                           url  num_segments  \n",
       "0  https://www.youtube.com/watch?v=ED3eypjlfrY            90  \n",
       "1  https://www.youtube.com/watch?v=uxF2IObEzZg            32  \n",
       "2  https://www.youtube.com/watch?v=5Kca3nOrefY            64  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "TRANSCRIPT_DIR = \"data/transcripts\"\n",
    "\n",
    "# 1. Find all JSON transcript files\n",
    "json_files = glob.glob(os.path.join(TRANSCRIPT_DIR, \"*.json\"))\n",
    "\n",
    "print(f\"Found {len(json_files)} transcript files in {TRANSCRIPT_DIR}:\")\n",
    "for path in json_files:\n",
    "    print(\" -\", os.path.basename(path))\n",
    "\n",
    "if not json_files:\n",
    "    raise FileNotFoundError(\n",
    "        f\"No JSON transcript files found in {TRANSCRIPT_DIR}. \"\n",
    "        \"Run Notebook 1 first to generate them.\"\n",
    "    )\n",
    "\n",
    "# 2. Quick overview of transcripts (for sanity check)\n",
    "summary = []\n",
    "for path in json_files:\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    summary.append({\n",
    "        \"video_id\": data[\"video_id\"],\n",
    "        \"title\": data[\"title\"],\n",
    "        \"url\": data[\"url\"],\n",
    "        \"num_segments\": len(data[\"segments\"])\n",
    "    })\n",
    "\n",
    "df_summary = pd.DataFrame(summary)\n",
    "df_summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74491593",
   "metadata": {},
   "source": [
    "2.2 Blog ingestion configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2038a09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "BLOG_LIST = [\n",
    "    {\n",
    "        \"id\": \"blog_mistakes\",\n",
    "        \"url\": \"https://www.prophero.com/the-most-common-property-investment-mistakes-that-can-easily-be-avoided/\",\n",
    "        \"title\": \"The Most Common Property Investment Mistakes That Can Easily Be Avoided\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"blog_capital_gains\",\n",
    "        \"url\": \"https://www.prophero.com/capital-gains-101-a-simplified-guide-for-smart-property-investing/\",\n",
    "        \"title\": \"Capital Gains 101: A Simplified Guide for Smart Property Investing\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"blog_rental_yield\",\n",
    "        \"url\": \"https://www.prophero.com/are-you-calculating-rental-yield-correctly/\",\n",
    "        \"title\": \"Are You Calculating Rental Yield Correctly?\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"blog_property_vs_shares\",\n",
    "        \"url\": \"https://www.prophero.com/property-vs-shares-whats-the-difference-which-is-better-for-you/\",\n",
    "        \"title\": \"Property vs Shares: What’s the Difference & Which is Better for You?\"\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb22a75",
   "metadata": {},
   "source": [
    "2.3 Helper functions. *basic_clean, fetch_blog_text, chunk_long_text*\n",
    "\n",
    " Clean = cleaning the text by removing new lines, extra spaces. \n",
    " Fetching the blog = dowloads and extracts the main content of PropHero blog articles\n",
    " Chunks = splits long article into smaller pieces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e49e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def basic_clean(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Simple cleaning function:\n",
    "    - remove extra line breaks\n",
    "    - collapse multiple spaces\n",
    "    - strip spaces at the beginning and end\n",
    "    \"\"\"\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "\n",
    "def fetch_blog_text(url: str) -> str:\n",
    "    \"\"\"\n",
    "    Download a PropHero blog article and return (roughly) the main text content.\n",
    "    \"\"\"\n",
    "    print(f\" Fetching blog: {url}\")\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    body = soup.body\n",
    "    if body is None:\n",
    "        print(\" No <body> found in page, returning empty text.\")\n",
    "        return \"\"\n",
    "\n",
    "    raw_text = body.get_text(separator=\" \")\n",
    "    cleaned_text = basic_clean(raw_text)\n",
    "    return cleaned_text\n",
    "\n",
    "\n",
    "def chunk_long_text(text: str, chunk_size: int = 800, overlap: int = 100):\n",
    "    \"\"\"\n",
    "    Split a long piece of text into overlapping chunks, measured in characters.\n",
    "    \"\"\"\n",
    "    chunks = []\n",
    "    start_idx = 0\n",
    "    text_len = len(text)\n",
    "\n",
    "    while start_idx < text_len:\n",
    "        end_idx = min(start_idx + chunk_size, text_len)\n",
    "        chunk_text = text[start_idx:end_idx].strip()\n",
    "\n",
    "        if chunk_text:\n",
    "            chunks.append(chunk_text)\n",
    "\n",
    "        if end_idx == text_len:\n",
    "            break\n",
    "\n",
    "        start_idx = end_idx - overlap\n",
    "\n",
    "    return chunks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ebb9eb",
   "metadata": {},
   "source": [
    "Reason why we dont chunk Yotube and Blog together is because they have different formats. Yotube --> already segmented text and Blog --> a big bolb of texty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c01b17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def preprocess_text(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Light preprocessing before chunking:\n",
    "    - Remove HTML tags\n",
    "    - Normalize whitespace\n",
    "    (No lemmatization, no aggressive changes to words)\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "\n",
    "    # 1) Strip leading/trailing spaces\n",
    "    text = text.strip()\n",
    "\n",
    "    # 2) Remove HTML tags like <p>, <br>, etc.\n",
    "    text = re.sub(r\"<[^>]+>\", \" \", text)\n",
    "\n",
    "    # 3) Normalize multiple spaces/newlines into a single space\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c632031f",
   "metadata": {},
   "source": [
    "2.4 Chunk Yotube Transcripts\n",
    "\n",
    "\n",
    " Chunk *(splitting the long transcript into smaller pieces, this will help us later for the retrieval)* / Embedding *(loaded setence-transformers/all-MiniLM-L6-v2. by converting every chunk into a vector, so that we can do semantic search)* / Store in vector DB. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f779522a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Processing prophero_video_1 (90 segments)\n",
      " Created 11 chunks for prophero_video_1\n",
      " Processing prophero_video_2 (32 segments)\n",
      " Created 5 chunks for prophero_video_2\n",
      " Processing prophero_video_3 (64 segments)\n",
      " Created 12 chunks for prophero_video_3\n",
      "\n",
      " Total chunks from all videos: 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_type</th>\n",
       "      <th>video_id</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>video</td>\n",
       "      <td>prophero_video_1</td>\n",
       "      <td>PropHero – Intro Video 1</td>\n",
       "      <td>https://www.youtube.com/watch?v=ED3eypjlfrY</td>\n",
       "      <td>0.00</td>\n",
       "      <td>42.24</td>\n",
       "      <td>Hi, my name is Michael Roger. I'm one of the c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>video</td>\n",
       "      <td>prophero_video_1</td>\n",
       "      <td>PropHero – Intro Video 1</td>\n",
       "      <td>https://www.youtube.com/watch?v=ED3eypjlfrY</td>\n",
       "      <td>42.24</td>\n",
       "      <td>72.56</td>\n",
       "      <td>rowth is about investing in an area where in t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>video</td>\n",
       "      <td>prophero_video_1</td>\n",
       "      <td>PropHero – Intro Video 1</td>\n",
       "      <td>https://www.youtube.com/watch?v=ED3eypjlfrY</td>\n",
       "      <td>72.56</td>\n",
       "      <td>104.48</td>\n",
       "      <td>e improvements. So think about renovation, add...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  source_type          video_id                     title  \\\n",
       "0       video  prophero_video_1  PropHero – Intro Video 1   \n",
       "1       video  prophero_video_1  PropHero – Intro Video 1   \n",
       "2       video  prophero_video_1  PropHero – Intro Video 1   \n",
       "\n",
       "                                           url  start     end  \\\n",
       "0  https://www.youtube.com/watch?v=ED3eypjlfrY   0.00   42.24   \n",
       "1  https://www.youtube.com/watch?v=ED3eypjlfrY  42.24   72.56   \n",
       "2  https://www.youtube.com/watch?v=ED3eypjlfrY  72.56  104.48   \n",
       "\n",
       "                                                text  \n",
       "0  Hi, my name is Michael Roger. I'm one of the c...  \n",
       "1  rowth is about investing in an area where in t...  \n",
       "2  e improvements. So think about renovation, add...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "CHUNK_SIZE = 600\n",
    "OVERLAP = 100\n",
    "\n",
    "def chunk_by_length(segments, chunk_size=600, overlap=100):\n",
    "    \"\"\"\n",
    "    Merge small transcript segments into larger overlapping chunks.\n",
    "    \"\"\"\n",
    "    chunks = []\n",
    "    current_chunk = \"\"\n",
    "    current_start = None\n",
    "    current_end = None\n",
    "\n",
    "    for seg in segments:\n",
    "        text = seg[\"text\"].strip()\n",
    "        start = seg[\"start\"]\n",
    "        end = seg[\"end\"]\n",
    "\n",
    "        if current_chunk == \"\":\n",
    "            current_chunk = text\n",
    "            current_start = start\n",
    "            current_end = end\n",
    "            continue\n",
    "\n",
    "        if len(current_chunk) + len(text) + 1 > chunk_size:\n",
    "            chunks.append({\n",
    "                \"text\": current_chunk.strip(),\n",
    "                \"start\": round(current_start, 2),\n",
    "                \"end\": round(current_end, 2)\n",
    "            })\n",
    "\n",
    "            \n",
    "            overlap_text = current_chunk[-overlap:] if overlap > 0 else \"\"\n",
    "            current_chunk = overlap_text + \" \" + text\n",
    "            current_start = start\n",
    "            current_end = end\n",
    "        else:\n",
    "            current_chunk += \" \" + text\n",
    "            current_end = end\n",
    "\n",
    "    if current_chunk:\n",
    "        chunks.append({\n",
    "            \"text\": current_chunk.strip(),\n",
    "            \"start\": round(current_start, 2),\n",
    "            \"end\": round(current_end, 2)\n",
    "        })\n",
    "\n",
    "    return chunks\n",
    "\n",
    "\n",
    "# === Loop through all transcript JSON files ===\n",
    "TRANSCRIPT_DIR = \"data/transcripts\"\n",
    "json_files = [f for f in os.listdir(TRANSCRIPT_DIR) if f.endswith(\".json\")]\n",
    "\n",
    "all_video_chunks = []\n",
    "\n",
    "for file_name in json_files:\n",
    "    path = os.path.join(TRANSCRIPT_DIR, file_name)\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    video_id = data[\"video_id\"]\n",
    "    title = data[\"title\"]\n",
    "    url = data[\"url\"]\n",
    "    segments = data[\"segments\"]\n",
    "\n",
    "    print(f\" Processing {video_id} ({len(segments)} segments)\")\n",
    "\n",
    "    # Apply linguistic preprocessing to each segment\n",
    "    for seg in segments:\n",
    "        seg[\"text\"] = preprocess_text(seg[\"text\"])\n",
    "\n",
    "    chunks = chunk_by_length(segments, CHUNK_SIZE, OVERLAP)\n",
    "    print(f\" Created {len(chunks)} chunks for {video_id}\")\n",
    "\n",
    "    # Save chunks with metadata\n",
    "    for ch in chunks:\n",
    "        all_video_chunks.append({\n",
    "            \"source_type\": \"video\",\n",
    "            \"video_id\": video_id,\n",
    "            \"title\": title,\n",
    "            \"url\": url,\n",
    "            \"start\": ch[\"start\"],\n",
    "            \"end\": ch[\"end\"],\n",
    "            \"text\": ch[\"text\"]\n",
    "        })\n",
    "\n",
    "print(f\"\\n Total chunks from all videos: {len(all_video_chunks)}\")\n",
    "df_video_chunks = pd.DataFrame(all_video_chunks)\n",
    "df_video_chunks.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f501acbe",
   "metadata": {},
   "source": [
    "2.5 Chunk Blogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941d683b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Fetching blog: https://www.prophero.com/the-most-common-property-investment-mistakes-that-can-easily-be-avoided/\n",
      " Blog 'The Most Common Property Investment Mistakes That Can Easily Be Avoided' → created 5 chunks\n",
      " Fetching blog: https://www.prophero.com/capital-gains-101-a-simplified-guide-for-smart-property-investing/\n",
      " Blog 'Capital Gains 101: A Simplified Guide for Smart Property Investing' → created 6 chunks\n",
      " Fetching blog: https://www.prophero.com/are-you-calculating-rental-yield-correctly/\n",
      " Blog 'Are You Calculating Rental Yield Correctly?' → created 4 chunks\n",
      " Fetching blog: https://www.prophero.com/property-vs-shares-whats-the-difference-which-is-better-for-you/\n",
      " Blog 'Property vs Shares: What’s the Difference & Which is Better for You?' → created 6 chunks\n",
      "\n",
      " Total blog chunks created: 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_type</th>\n",
       "      <th>video_id</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blog</td>\n",
       "      <td>blog_mistakes</td>\n",
       "      <td>The Most Common Property Investment Mistakes T...</td>\n",
       "      <td>https://www.prophero.com/the-most-common-prope...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>How it works About us Data and AI Press and Bl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blog</td>\n",
       "      <td>blog_mistakes</td>\n",
       "      <td>The Most Common Property Investment Mistakes T...</td>\n",
       "      <td>https://www.prophero.com/the-most-common-prope...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>t. Mistake #1. Using your emotions to guide yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blog</td>\n",
       "      <td>blog_mistakes</td>\n",
       "      <td>The Most Common Property Investment Mistakes T...</td>\n",
       "      <td>https://www.prophero.com/the-most-common-prope...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ke #2: You do not have to invest in property w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  source_type       video_id  \\\n",
       "0        blog  blog_mistakes   \n",
       "1        blog  blog_mistakes   \n",
       "2        blog  blog_mistakes   \n",
       "\n",
       "                                               title  \\\n",
       "0  The Most Common Property Investment Mistakes T...   \n",
       "1  The Most Common Property Investment Mistakes T...   \n",
       "2  The Most Common Property Investment Mistakes T...   \n",
       "\n",
       "                                                 url start   end  \\\n",
       "0  https://www.prophero.com/the-most-common-prope...  None  None   \n",
       "1  https://www.prophero.com/the-most-common-prope...  None  None   \n",
       "2  https://www.prophero.com/the-most-common-prope...  None  None   \n",
       "\n",
       "                                                text  \n",
       "0  How it works About us Data and AI Press and Bl...  \n",
       "1  t. Mistake #1. Using your emotions to guide yo...  \n",
       "2  ke #2: You do not have to invest in property w...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BLOG_CHUNK_SIZE = 800  \n",
    "BLOG_OVERLAP = 100\n",
    "\n",
    "all_blog_chunks = [] \n",
    "\n",
    "for blog in BLOG_LIST:\n",
    "    blog_id = blog[\"id\"]\n",
    "    url = blog[\"url\"]\n",
    "    title = blog[\"title\"]\n",
    "\n",
    "    try:\n",
    "        # 1. Fetch the blog article\n",
    "        blog_text = fetch_blog_text(url)\n",
    "        if not blog_text:\n",
    "            print(f\" Empty content for blog {blog_id}, skipping.\")\n",
    "            continue\n",
    "\n",
    "        # 2. Apply preprocessing (clean + lemmatize)\n",
    "        clean_blog_text = preprocess_text(blog_text)\n",
    "\n",
    "        # 3. Split the clean text into overlapping chunks\n",
    "        blog_chunks = chunk_long_text(\n",
    "            clean_blog_text,\n",
    "            chunk_size=BLOG_CHUNK_SIZE,\n",
    "            overlap=BLOG_OVERLAP\n",
    "        )\n",
    "\n",
    "        print(f\" Blog '{title}' → created {len(blog_chunks)} chunks\")\n",
    "\n",
    "        # 4. Store chunks with metadata\n",
    "        for i, chunk_text in enumerate(blog_chunks):\n",
    "            all_blog_chunks.append({\n",
    "                \"source_type\": \"blog\",\n",
    "                \"video_id\": blog_id,  \n",
    "                \"title\": title,\n",
    "                \"url\": url,\n",
    "                \"start\": None,\n",
    "                \"end\": None,\n",
    "                \"text\": chunk_text\n",
    "            })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\" Error while processing blog '{title}': {e}\")\n",
    "\n",
    "print(f\"\\n Total blog chunks created: {len(all_blog_chunks)}\")\n",
    "\n",
    "# Optional: preview\n",
    "import pandas as pd\n",
    "df_blog_chunks = pd.DataFrame(all_blog_chunks)\n",
    "df_blog_chunks.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8a76fb",
   "metadata": {},
   "source": [
    "We chunk separately Yotube videos vs text because Yotube videos transcripts come already semi-chunked (with segments), blogs are chunked differently (with continious text) and not already segmented.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532f0748",
   "metadata": {},
   "source": [
    "2.6 Merging Yotube + Blog Chunks into one dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1cb1594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Video chunks: 28\n",
      " Blog chunks : 21\n",
      " Total chunks: 49\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_type</th>\n",
       "      <th>video_id</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>video</td>\n",
       "      <td>prophero_video_2</td>\n",
       "      <td>PropHero – Intro Video 2</td>\n",
       "      <td>https://www.youtube.com/watch?v=uxF2IObEzZg</td>\n",
       "      <td>53.28</td>\n",
       "      <td>74.72</td>\n",
       "      <td>led on bringing the best talent to the team. W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>blog</td>\n",
       "      <td>blog_property_vs_shares</td>\n",
       "      <td>Property vs Shares: What’s the Difference &amp; Wh...</td>\n",
       "      <td>https://www.prophero.com/property-vs-shares-wh...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0 minute webinar here. This will give you tips...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>blog</td>\n",
       "      <td>blog_property_vs_shares</td>\n",
       "      <td>Property vs Shares: What’s the Difference &amp; Wh...</td>\n",
       "      <td>https://www.prophero.com/property-vs-shares-wh...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>onth. The stock market is more volatile The st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>blog</td>\n",
       "      <td>blog_property_vs_shares</td>\n",
       "      <td>Property vs Shares: What’s the Difference &amp; Wh...</td>\n",
       "      <td>https://www.prophero.com/property-vs-shares-wh...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>difference for you and help you choose the rig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>video</td>\n",
       "      <td>prophero_video_3</td>\n",
       "      <td>PropHero – Intro Video 3</td>\n",
       "      <td>https://www.youtube.com/watch?v=5Kca3nOrefY</td>\n",
       "      <td>42.00</td>\n",
       "      <td>78.24</td>\n",
       "      <td>perties or do proper due diligence. Number two...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   source_type                 video_id  \\\n",
       "13       video         prophero_video_2   \n",
       "45        blog  blog_property_vs_shares   \n",
       "47        blog  blog_property_vs_shares   \n",
       "44        blog  blog_property_vs_shares   \n",
       "17       video         prophero_video_3   \n",
       "\n",
       "                                                title  \\\n",
       "13                           PropHero – Intro Video 2   \n",
       "45  Property vs Shares: What’s the Difference & Wh...   \n",
       "47  Property vs Shares: What’s the Difference & Wh...   \n",
       "44  Property vs Shares: What’s the Difference & Wh...   \n",
       "17                           PropHero – Intro Video 3   \n",
       "\n",
       "                                                  url  start    end  \\\n",
       "13        https://www.youtube.com/watch?v=uxF2IObEzZg  53.28  74.72   \n",
       "45  https://www.prophero.com/property-vs-shares-wh...    NaN    NaN   \n",
       "47  https://www.prophero.com/property-vs-shares-wh...    NaN    NaN   \n",
       "44  https://www.prophero.com/property-vs-shares-wh...    NaN    NaN   \n",
       "17        https://www.youtube.com/watch?v=5Kca3nOrefY  42.00  78.24   \n",
       "\n",
       "                                                 text  \n",
       "13  led on bringing the best talent to the team. W...  \n",
       "45  0 minute webinar here. This will give you tips...  \n",
       "47  onth. The stock market is more volatile The st...  \n",
       "44  difference for you and help you choose the rig...  \n",
       "17  perties or do proper due diligence. Number two...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_chunks = list(all_video_chunks) + list(all_blog_chunks)\n",
    "\n",
    "num_video_chunks = len(all_video_chunks)\n",
    "num_blog_chunks = len(all_blog_chunks)\n",
    "num_total_chunks = len(all_chunks)\n",
    "\n",
    "print(f\" Video chunks: {num_video_chunks}\")\n",
    "print(f\" Blog chunks : {num_blog_chunks}\")\n",
    "print(f\" Total chunks: {num_total_chunks}\")\n",
    "\n",
    "# Create DataFrame for exploration\n",
    "df_all_chunks = pd.DataFrame(all_chunks)\n",
    "\n",
    "# Preview a few random examples\n",
    "df_all_chunks.sample(5, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c629da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Saved merged chunks to:\n",
      " - data/processed/prophero_all_chunks.json\n",
      " - data/processed/prophero_all_chunks.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "os.makedirs(\"data/processed\", exist_ok=True)\n",
    "\n",
    "# Save as JSON (keeps full structure)\n",
    "json_path = \"data/processed/prophero_all_chunks.json\"\n",
    "with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(all_chunks, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# Saving it into CSV for quick viewing in Excel\n",
    "csv_path = \"data/processed/prophero_all_chunks.csv\"\n",
    "df_all_chunks.to_csv(csv_path, index=False)\n",
    "\n",
    "print(\" Saved merged chunks to:\")\n",
    "print(\" -\", json_path)\n",
    "print(\" -\", csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044ded44",
   "metadata": {},
   "source": [
    "2.7 Creating the embedding for all chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c390a171",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "shutil.rmtree(\"data/chroma_db\", ignore_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be84074",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\macat\\anaconda3\\envs\\langchain-mq\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded embedding model: sentence-transformers/all-MiniLM-L6-v2\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "emb_model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "emb_model = SentenceTransformer(emb_model_name)\n",
    "\n",
    "print(f\"Loaded embedding model: {emb_model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f6b59e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks to embed: 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 2/2 [00:12<00:00,  6.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape: (49, 384)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "texts = [c[\"text\"] for c in all_chunks]\n",
    "print(f\"Number of chunks to embed: {len(texts)}\")\n",
    "\n",
    "embeddings = emb_model.encode(texts, show_progress_bar=True)\n",
    "\n",
    "print(\"Embeddings shape:\", embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daadaab7",
   "metadata": {},
   "source": [
    "\"sentence-transformers/all-MiniLM-L6-v2\", is the \"swet spot\" model.\n",
    "\n",
    "- Good semantic Quality:  It performs very well on typical semantic similarity tasks (question --> answer, paragraphs), perfect for RAG. \n",
    "\n",
    "- Fast & lightweight: Fast embedding creation, low memory usage and easy to run in a normal laptop."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699147bc",
   "metadata": {},
   "source": [
    "2.8 Store chunks + embeddings in Chroma DB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abf29f6",
   "metadata": {},
   "source": [
    "Chroma stores not only the embeddings but also metadata like source type, video/blog ID, title, URL and timestamps.\n",
    "Chroma’s metadata layer only accepts primitive types (strings, numbers, booleans), so we had to ensure we never send None values.\n",
    "\n",
    "We built a build_metadata helper that cleans each metadata dictionary and removes any None values before insertion.\n",
    "Then we use a PersistentClient to save all embeddings and metadata in a local folder (data/chroma_db), so our chatbot’s knowledge base is permanently stored and can be reused in later notebooks and in the UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbdc79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_metadata(chunk: dict, idx: int) -> dict:\n",
    "    \"\"\"\n",
    "    Build metadata for each chunk, including a unique chunk_id.\n",
    "    \"\"\"\n",
    "\n",
    "    raw_meta = {\n",
    "        \"source_type\": chunk.get(\"source_type\"),\n",
    "        \"video_id\": chunk.get(\"video_id\"),\n",
    "        \"title\": chunk.get(\"title\"),\n",
    "        \"url\": chunk.get(\"url\"),\n",
    "        \"start\": float(chunk[\"start\"]) if chunk.get(\"start\") is not None else None,\n",
    "        \"end\": float(chunk[\"end\"]) if chunk.get(\"end\") is not None else None,\n",
    "\n",
    "\n",
    "        \"chunk_id\": f\"{chunk.get('source_type')}_{chunk.get('video_id')}_{idx}\"\n",
    "    }\n",
    "\n",
    "    return {k: v for k, v in raw_meta.items() if v is not None}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56eb4d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 49 chunks correctly.\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "\n",
    "persist_dir = \"data/chroma_db\"\n",
    "\n",
    "client = chromadb.PersistentClient(path=persist_dir)\n",
    "\n",
    "collection_name = \"prophero_knowledge\"\n",
    "collection = client.get_or_create_collection(\n",
    "    name=collection_name,\n",
    "    metadata={\"hnsw:space\": \"cosine\"} \n",
    ")\n",
    "\n",
    "documents = [c[\"text\"] for c in all_chunks]\n",
    "metadatas = [build_metadata(c, i) for i, c in enumerate(all_chunks)]\n",
    "ids = [m[\"chunk_id\"] for m in metadatas]  \n",
    "\n",
    "collection.add(\n",
    "    ids=ids,\n",
    "    documents=documents,\n",
    "    metadatas=metadatas,\n",
    "    embeddings=embeddings.tolist(),\n",
    ")\n",
    "\n",
    "print(\"Saved\", len(ids), \"chunks correctly.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051affa8",
   "metadata": {},
   "source": [
    "**Summary**\n",
    "\n",
    "\n",
    "In Notebook 2, I focused on indexing, cleaning, and embedding all textual data (YouTube transcripts + PropHero blogs) to prepare it for the Question-Answering stage of the RAG system.\n",
    "\n",
    "First, I re-used the cleaned video transcripts created in Notebook 1 and ingested several PropHero blog posts.\n",
    "I applied helper functions that performed additional cleaning to improve the quality of embeddings.\n",
    "\n",
    "Next, I used LangChain’s RecursiveCharacterTextSplitter to chunk both data sources into overlapping segments, ensuring that each piece maintained context.\n",
    "I then encoded all chunks into vector embeddings using the sentence-transformers/all-MiniLM-L6-v2 model and stored them together in a persistent Chroma database.\n",
    "\n",
    "This notebook therefore represents the indexing and embedding stage of the project pipeline—transforming all PropHero textual data (videos and blogs) into a structured, searchable vector format that powers the final Question-Answering system."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-mq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
